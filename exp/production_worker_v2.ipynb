{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Gifty SOTA Worker: 10-Dimension Matrix (VLM)\n",
                "\n",
                "This worker implements the **Gifty 10-Dimensions Matrix** for product scoring.\n",
                "It uses **Qwen2-VL-7B-Instruct** to perceive products visually and psychometrically.\n",
                "\n",
                "### The 10 Axes (0.0 - 1.0):\n",
                "1. **Wow-Factor** (Surprise)\n",
                "2. **Warmth** (Emotional Temp)\n",
                "3. **Romance** (Intimacy)\n",
                "4. **Practicality** (Utility)\n",
                "5. **Usage Frequency**\n",
                "6. **Occasion Versatility**\n",
                "7. **Aesthetics** (Visual Value)\n",
                "8. **Social Risk**\n",
                "9. **Age Suitability** (Vector)\n",
                "10. **Gender Bias** (Vector)\n",
                "\n",
                "### Output\n",
                "Generates a structured JSON object stored in `llm_gift_vector`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip -q install -U transformers accelerate bitsandbytes qwen_vl_utils requests Pillow tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import re\n",
                "import logging\n",
                "import sys\n",
                "import torch\n",
                "import requests\n",
                "from PIL import Image\n",
                "from io import BytesIO\n",
                "from kaggle_secrets import UserSecretsClient\n",
                "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
                "from qwen_vl_utils import process_vision_info\n",
                "\n",
                "# Setup\n",
                "API_BASE_URL = \"https://api.giftyai.ru\"\n",
                "DEBUG = True\n",
                "try:\n",
                "    user_secrets = UserSecretsClient()\n",
                "    INTERNAL_TOKEN = user_secrets.get_secret(\"INTERNAL_API_TOKEN\")\n",
                "except:\n",
                "    INTERNAL_TOKEN = os.getenv(\"INTERNAL_API_TOKEN\", \"default_token\")\n",
                "\n",
                "MODEL_ID = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
                "MODEL_VERSION = \"v3.0-matrix-10d\"\n",
                "\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')\n",
                "logger = logging.getLogger(\"GiftyMatrixWorker\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_load",
            "metadata": {},
            "outputs": [],
            "source": [
                "logger.info(\"Loading Qwen2-VL-7B...\")\n",
                "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
                "    MODEL_ID, torch_dtype=\"auto\", device_map=\"auto\"\n",
                ")\n",
                "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
                "model.eval()\n",
                "logger.info(\"Model Loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "prompt_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "SYSTEM_PROMPT = \"\"\"You are an expert luxury gift buyer and psychologist.\n",
                "Your task is to evaluate a product across 10 psychological dimensions.\n",
                "Analyze the image (packaging, quality) and the text triggers.\n",
                "\n",
                "OUTPUT FORMAT: Return ONLY a valid JSON object. No markdown, no pre-text.\n",
                "JSON Structure:\n",
                "{\n",
                "  \"reasoning\": \"Brief analysis of visual quality, vibe, and target audience (2-3 sentences).\",\n",
                "  \"scores\": {\n",
                "    \"wow_factor\": 0.0-1.0,      // Surprise, delight, uniqueness\n",
                "    \"warmth\": 0.0-1.0,          // Cozy, emotional, handcrafted feel vs Cold/Tech\n",
                "    \"romance\": 0.0-1.0,         // Intimacy level (High=Partner only, Low=Colleague)\n",
                "    \"practicality\": 0.0-1.0,    // Utility vs Decor/Fun\n",
                "    \"usage_frequency\": 0.0-1.0, // Daily vs Once/Seasonal\n",
                "    \"occasion_versatility\": 0.0-1.0, // Universal (Birthday) vs Niche (Wedding)\n",
                "    \"aesthetics\": 0.0-1.0,      // Visual premium feel, packaging quality\n",
                "    \"social_risk\": 0.0-1.0,     // Chance of being awkward/useless (High risk = Clothes, Perfume)\n",
                "    \"giftability_total\": 0.0-1.0 // Overall suitability as a gift\n",
                "  },\n",
                "  \"demographics\": {\n",
                "    \"gender\": \"male\" | \"female\" | \"unisex\",\n",
                "    \"age_min\": int,\n",
                "    \"age_max\": int\n",
                "  }\n",
                "}\n",
                "\"\"\"\n",
                "\n",
                "def get_image(url):\n",
                "    try:\n",
                "        if not url: return None\n",
                "        resp = requests.get(url, timeout=5)\n",
                "        return Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
                "    except: return None\n",
                "\n",
                "def extract_json(text):\n",
                "    try:\n",
                "        # Find first { and last }\n",
                "        text = text[text.find('{'):text.rfind('}')+1]\n",
                "        return json.loads(text)\n",
                "    except:\n",
                "        return None\n",
                "\n",
                "def process_one(item):\n",
                "    img = get_image(item.get('image_url'))\n",
                "    \n",
                "    user_content = [\n",
                "        {\"type\": \"text\", \"text\": f\"Product: {item.get('title')}\\nCategory: {item.get('category')}\\nPrice: {item.get('price')}\"}\n",
                "    ]\n",
                "    if img:\n",
                "        user_content.insert(0, {\"type\": \"image\", \"image\": item['image_url']})\n",
                "        \n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
                "        {\"role\": \"user\", \"content\": user_content}\n",
                "    ]\n",
                "    \n",
                "    text_in = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    image_inputs, _ = process_vision_info(messages)\n",
                "    \n",
                "    inputs = processor(\n",
                "        text=[text_in], images=image_inputs, padding=True, return_tensors=\"pt\"\n",
                "    ).to(model.device)\n",
                "    \n",
                "    # Generate\n",
                "    generated_ids = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
                "    gen_text = processor.batch_decode(\n",
                "        generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
                "    )[0]\n",
                "    \n",
                "    # Parse Output\n",
                "    # Remove prompt from output (Qwen sometimes echoes)\n",
                "    if \"OUTPUT FORMAT\" in gen_text:\n",
                "        response_only = gen_text.split(\"assistant\\n\")[-1]\n",
                "    else:\n",
                "        response_only = gen_text\n",
                "        \n",
                "    data = extract_json(response_only)\n",
                "    \n",
                "    if not data:\n",
                "        logger.error(f\"Failed to parse JSON for {item.get('gift_id')}. Raw: {response_only[:100]}...\")\n",
                "        return None\n",
                "        \n",
                "    return data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "loop",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "headers = {\"X-Internal-Token\": INTERNAL_TOKEN}\n",
                "\n",
                "logger.info(\"Starting SOTA Loop...\")\n",
                "while True:\n",
                "    try:\n",
                "        # 1. Fetch\n",
                "        resp = requests.get(f\"{API_BASE_URL}/internal/scoring/tasks?limit=5\", headers=headers)\n",
                "        tasks = resp.json()\n",
                "        if not tasks:\n",
                "            time.sleep(60)\n",
                "            continue\n",
                "            \n",
                "        logger.info(f\"Processing batch of {len(tasks)}\")\n",
                "        results = []\n",
                "        for t in tasks:\n",
                "            try:\n",
                "                data = process_one(t)\n",
                "                if data:\n",
                "                    res = {\n",
                "                        \"gift_id\": t['gift_id'],\n",
                "                        \"llm_gift_score\": data['scores'].get('giftability_total', 0.0),\n",
                "                        \"llm_gift_reasoning\": data.get('reasoning', ''),\n",
                "                        \"llm_gift_vector\": data,\n",
                "                        \"llm_scoring_model\": MODEL_ID,\n",
                "                        \"llm_scoring_version\": MODEL_VERSION\n",
                "                    }\n",
                "                    results.append(res)\n",
                "            except Exception as e:\n",
                "                logger.error(f\"Error item {t['gift_id']}: {e}\")\n",
                "        \n",
                "        if results:\n",
                "            requests.post(f\"{API_BASE_URL}/internal/scoring/submit\", json={\"results\": results}, headers=headers)\n",
                "            logger.info(f\"Submitted {len(results)}\")\n",
                "            \n",
                "    except Exception as e:\n",
                "        logger.error(f\"Loop Error: {e}\")\n",
                "        time.sleep(30)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}