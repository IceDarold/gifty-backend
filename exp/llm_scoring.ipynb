{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f91cab84",
            "metadata": {},
            "source": [
                "# LLM 8B Scoring (Probability)\n",
                "\n",
                "This notebook implements product scoring using a local LLM (Qwen2.5-7B-Instruct) in 4-bit quantization. It outputs a probability score for being a gift."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6e636e6c",
            "metadata": {},
            "source": [
                "### Cell 1 — install"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce0ea0cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip -q install -U transformers accelerate bitsandbytes sentencepiece pandas tqdm"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "06fcdd43",
            "metadata": {},
            "source": [
                "### Cell 2 — load model (4-bit)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "be677971",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
                "\n",
                "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"  # 8B-ish, отлично для RU/EN\n",
                "\n",
                "bnb = BitsAndBytesConfig(\n",
                "    load_in_4bit=True,\n",
                "    bnb_4bit_compute_dtype=torch.float16,\n",
                "    bnb_4bit_use_double_quant=True,\n",
                "    bnb_4bit_quant_type=\"nf4\",\n",
                ")\n",
                "\n",
                "tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_ID,\n",
                "    quantization_config=bnb,\n",
                "    device_map=\"auto\",\n",
                ")\n",
                "model.eval()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc07fcad",
            "metadata": {},
            "source": [
                "### Cell 3 — prompt + scoring двух меток (без генерации)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aad7c87d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn.functional as F\n",
                "\n",
                "SYSTEM = \"You are a strict classifier. Answer with ONLY one token: GIFT or NOT_GIFT.\"\n",
                "\n",
                "def build_prompt(title, category=\"\", store=\"\", price_rub=None):\n",
                "    price_txt = \"\" if price_rub is None else f\"{price_rub}\"\n",
                "    user = f\"\"\"Decide if this product is a good gift item for most people.\n",
                "If it is mostly a utilitarian supply/chemical/spare part/consumable -> NOT_GIFT.\n",
                "If it is a presentable gift item (decor, gadgets, jewelry, toys, hobby items) -> GIFT.\n",
                "\n",
                "Product:\n",
                "- title: {title}\n",
                "- category: {category}\n",
                "- store: {store}\n",
                "- price_rub: {price_txt}\n",
                "Answer:\"\"\"\n",
                "    # Qwen chat template\n",
                "    msgs = [\n",
                "        {\"role\": \"system\", \"content\": SYSTEM},\n",
                "        {\"role\": \"user\", \"content\": user},\n",
                "    ]\n",
                "    return tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
                "\n",
                "@torch.no_grad()\n",
                "def score_label(prompt: str, label: str) -> float:\n",
                "    # Score logprob of label completion tokens given prompt\n",
                "    full = prompt + label\n",
                "    enc_full = tok(full, return_tensors=\"pt\").to(model.device)\n",
                "    enc_prompt = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
                "\n",
                "    input_ids = enc_full[\"input_ids\"]\n",
                "    # positions that correspond to label tokens\n",
                "    prompt_len = enc_prompt[\"input_ids\"].shape[1]\n",
                "    logits = model(**enc_full).logits  # [B, T, V]\n",
                "\n",
                "    # logprobs for tokens t at positions >= prompt_len\n",
                "    # token at position i is predicted by logits at i-1\n",
                "    label_ids = input_ids[:, prompt_len:]\n",
                "    start = prompt_len - 1\n",
                "    lp = 0.0\n",
                "    for j in range(label_ids.shape[1]):\n",
                "        token_id = label_ids[0, j].item()\n",
                "        logp = F.log_softmax(logits[0, start + j, :], dim=-1)[token_id].item()\n",
                "        lp += logp\n",
                "    return lp\n",
                "\n",
                "@torch.no_grad()\n",
                "def giftability_llm(title, category=\"\", store=\"\", price_rub=None):\n",
                "    prompt = build_prompt(title, category, store, price_rub)\n",
                "    s_gift = score_label(prompt, \" GIFT\")\n",
                "    s_not  = score_label(prompt, \" NOT_GIFT\")\n",
                "    # convert to probability-like score\n",
                "    p_gift = float(torch.softmax(torch.tensor([s_not, s_gift]), dim=0)[1].item())\n",
                "    return p_gift"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "933083c8",
            "metadata": {},
            "source": [
                "### Cell 4 — Load Data\n",
                "\n",
                "Reading from CSV with `;` separator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8af925e7",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Update path to your csv file\n",
                "df = pd.read_csv('products.csv', sep=';')\n",
                "df.head(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2ab10100-0cf7-40dd-b8ca-9592f9f3e8e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import re\n",
                "\n",
                "# --- 3) Normalize columns (Russian -> internal) ---\n",
                "COLMAP = {\n",
                "    \"Название товара\": \"title\",\n",
                "    \"Артикул\": \"sku\",\n",
                "    \"Цена товара\": \"price\",\n",
                "    \"Категория товара\": \"category\",\n",
                "    \"Изображение\": \"image_url\",\n",
                "    \"Название магазина\": \"store_name\",\n",
                "    \"Название маркетплейса\": \"marketplace_name\",\n",
                "    \"Рейтинг\": \"rating\",\n",
                "    \"Партнерская ссылка\": \"partner_url\",\n",
                "    \"Модель оплаты\": \"pay_model\",\n",
                "    \"Комиссия\": \"commission\",\n",
                "    \"Потенциальная комиссия\": \"potential_commission\",\n",
                "    \"Цена клика\": \"cpc\",\n",
                "    \"Юридические данные продавца\": \"legal_text\",\n",
                "}\n",
                "\n",
                "df = df.rename(columns={k: v for k, v in COLMAP.items() if k in df.columns})\n",
                "\n",
                "required = [\"title\", \"sku\", \"price\", \"category\", \"image_url\", \"partner_url\"]\n",
                "missing = [c for c in required if c not in df.columns]\n",
                "if missing:\n",
                "    raise ValueError(f\"Missing required columns after rename: {missing}\")\n",
                "\n",
                "def to_float_safe(x):\n",
                "    if pd.isna(x):\n",
                "        return np.nan\n",
                "    if isinstance(x, (int, float)):\n",
                "        return float(x)\n",
                "    s = str(x).replace(\" \", \"\").replace(\",\", \".\")\n",
                "    s = re.sub(r\"[^0-9.]\", \"\", s)\n",
                "    try:\n",
                "        return float(s) if s else np.nan\n",
                "    except:\n",
                "        return np.nan\n",
                "\n",
                "df[\"price\"] = df[\"price\"].apply(to_float_safe)\n",
                "if \"rating\" in df.columns:\n",
                "    df[\"rating\"] = df[\"rating\"].apply(to_float_safe)\n",
                "\n",
                "# Keep essentials\n",
                "df = df.dropna(subset=[\"title\", \"sku\", \"category\", \"image_url\", \"partner_url\"]).reset_index(drop=True)\n",
                "print(\"Clean rows:\", len(df))\n",
                "df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ad17ba67",
            "metadata": {},
            "source": [
                "### Cell 5 — прогон на сэмпле (например 200 строк)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c0e5e9bb",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "\n",
                "df_sample = df.sample(min(200, len(df)), random_state=0).copy()\n",
                "\n",
                "scores = []\n",
                "for _, r in tqdm(df_sample.iterrows(), total=len(df_sample)):\n",
                "    p_gift = giftability_llm(\n",
                "        title=r.get(\"title\",\"\"),\n",
                "        category=r.get(\"category\",\"\"),\n",
                "        store=r.get(\"store_name\",\"\"),\n",
                "        price_rub=r.get(\"price\", None), # 'price' is the normalized column\n",
                "    )\n",
                "    scores.append(p_gift)\n",
                "\n",
                "df_sample[\"llm_gift_score\"] = scores\n",
                "\n",
                "df_sample[[\"title\",\"category\",\"llm_gift_score\"]].head(10)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}